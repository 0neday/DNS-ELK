input {
    # Listen for logs from Filebeat on default port
    beats {
        port => 5044
    type => "logs"
    }
}

filter {
    # These grok patterns will match on 3 types of the dnsmaq logs and use custom patterns
    grok {
        patterns_dir => ["./patterns"]
        match=> { "message" => ["^%{logdate:LOGDATE} dnsmasq\[[\d]+\]\: query\[[\w]+\] %{domain:DOMAIN} from %{clientip:CLIENTIP}"
        , "^%{logdate:LOGDATE} dnsmasq\[[\d]+\]\: reply %{domain:DOMAIN} is %{ip:IP}", "^%{logdate:LOGDATE} dnsmasq\[[\d]+\]\: %{blocklist:BLOCKLIST} %{domain:DOMAIN} is %{ip:IP}"]
        }
    }
    # Standardize the @timestamp so it matches LOGDATE
    date {
        match => [ "LOGDATE", "MMM dd HH:mm:ss", "MMM  d HH:mm:ss", "ISO8601" ]
    }
    # Enrich logs with GeoIP geolocation data
    geoip {
        source => "IP"
    }
}

output {
    # Ship the logs to Elasticsearch and output to screen
    elasticsearch {
        # Specify your Elasticsearch IP
        hosts => ["localhost:9200"]
        index => "logstash-dnsmasq-%{+YYYY.MM.dd}"
    }
    stdout {
        codec => rubydebug
    }
}
